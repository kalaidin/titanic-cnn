{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "The main idea is to use no hand crafted features at all. Let the model do it itself.\n\nWe'll be applying 1d convolution on learned character embeddings of raw passenger text data (names, tickets, etc.). \n\nThis, combined with numeric raw features should probably give around 0.8 accuracy (currently got 0.80861 at the leaderboard but this is subject to some randomness :).\n\nAny feedback is welcome.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from keras.layers import Input, Dense, Activation, merge, Conv1D, Dropout, Embedding, GlobalMaxPooling1D\nfrom keras.models import Model\nfrom keras.callbacks import Callback\nfrom keras.optimizers import Adam",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "labels = train_df.Survived.values\ntrain_df.drop('Survived', axis=1, inplace=True)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train_df = train_df.fillna(0)\ntest_df = test_df.fillna(0)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train_df[\"Sex\"] = train_df[\"Sex\"].apply(lambda x: 1 if x == \"male\" else 0)\ntest_df[\"Sex\"] = train_df[\"Sex\"].apply(lambda x: 1 if x == \"male\" else 0)\ntrain_df[\"Cabin\"] = train_df[\"Cabin\"].apply(lambda x: 1 if x != 0 else 0)\ntest_df[\"Cabin\"] = train_df[\"Cabin\"].apply(lambda x: 1 if x != 0 else 0)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train_df.head()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "numeric_features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\"]",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_numeric = train_df[numeric_features].values",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_numeric.shape",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "text_features = [\"Name\", \"Ticket\", \"Embarked\"]",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def load_data(symbols):\n    vocab = {}\n    words = list(symbols.lower())\n    for i, word in enumerate(words):\n        if word not in vocab:\n            vocab[word] = len(vocab)\n    print('corpus length:', len(words))\n    print('vocab size:', len(vocab))\n    return vocab",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "all_symbols = \"\"\nfor x in train_df[text_features].values:\n    all_symbols += \" \".join(map(str, x)) + \" \"",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "vocab = load_data(all_symbols)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "max_name_length = train_df.Name.apply(len).max()\nmax_ticket_length = train_df.Ticket.apply(len).max()\ntrain_df[\"Embarked\"] = train_df.Embarked.apply(lambda x: \"s\" if x == 0 else x.lower())\nmax_embarked_length = train_df.Embarked.apply(len).max()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_text = np.zeros((891, max_name_length + max_ticket_length + max_embarked_length))",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "for e, i in enumerate(train_df[text_features].iterrows()):\n    name = i[1][\"Name\"].lower()\n    ticket = i[1][\"Ticket\"].lower()\n    emb = i[1][\"Embarked\"].lower()\n    for p, w in enumerate(name):\n        X_text[e, p] = vocab[w]\n    for p, w in enumerate(ticket):\n        X_text[e, p + max_name_length] = vocab[w]\n    for p, w in enumerate(emb):\n        X_text[e, p + max_name_length + max_ticket_length] = vocab[w] ",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_text.shape",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "split_n = int(0.25 * len(train_df))",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_text_train, X_text_test = X_text[split_n:], X_text[:split_n]\nX_numeric_train, X_numeric_test = X_numeric[split_n:], X_numeric[:split_n]\ny_train, y_test = labels[split_n:], labels[:split_n]",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "y_train.mean(), y_test.mean()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "numeric_input = Input(shape=(7,), name='numeric_input')\ny = Dense(3)(numeric_input)\n\ntext_input = Input(shape=(101,), name='text_input')\nx = Embedding(len(vocab), 64, input_length=101) (text_input)\nx = Conv1D(16, 4, activation='relu', subsample_length=1)(x)\nx = GlobalMaxPooling1D()(x)\nx = Dense(16)(x)\nx = Dropout(0.5)(x)\n\nconv_output = Dense(1, activation='sigmoid', name='conv_output')(x)\n\nx = merge([x, y], mode='concat')\n\npreds = Dense(1, activation='sigmoid', name='main_output')(x)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "adam = Adam(lr=0.0001)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model = Model(input=[numeric_input, text_input], output=[preds, conv_output])\nmodel.compile(loss='binary_crossentropy', \n              optimizer=adam,\n              metrics=[\"accuracy\"],\n              loss_weights=[1, 0.2])",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "model.summary()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "N_EPOCHS = 100",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#The code below runs about 22 sec on my Titan X",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "%%time\ntrain_scores = []\ntest_scores = []\nfor epoch in range(N_EPOCHS):\n    model.fit([X_numeric_train, X_text_train], [y_train, y_train], nb_epoch=1, batch_size=8, verbose=0)\n    probas = model.predict([X_numeric_train, X_text_train])[0]\n    a, r, l = accuracy_score(y_train, probas > 0.5), roc_auc_score(y_train, probas), log_loss(y_train, probas)\n    train_scores.append((a, r, l))\n    probas = model.predict([X_numeric_test, X_text_test])[0]\n    a, r, l = accuracy_score(y_test, probas > 0.5), roc_auc_score(y_test, probas), log_loss(y_test, probas)\n    test_scores.append((a, r, l))",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "probas = model.predict([X_numeric_test, X_text_test])[0]\nprobas.mean()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train_scores = pd.DataFrame([x for x in train_scores], columns=[\"accuracy\", \"roc_auc\", \"log_loss\"])\ntest_scores = pd.DataFrame([x for x in test_scores], columns=[\"accuracy\", \"roc_auc\", \"log_loss\"])\ntrain_scores[\"phase\"] = \"train\"\ntest_scores[\"phase\"] = \"test\"\nscores = pd.concat([train_scores, test_scores])\nscores[\"epoch\"] = scores.index",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "plt.plot(scores[scores.phase==\"train\"].epoch, scores[scores.phase==\"train\"].roc_auc)\nplt.plot(scores[scores.phase==\"test\"].epoch, scores[scores.phase==\"test\"].roc_auc)\nplt.show()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "plt.plot(scores[scores.phase==\"train\"].epoch, scores[scores.phase==\"train\"].accuracy)\nplt.plot(scores[scores.phase==\"test\"].epoch, scores[scores.phase==\"test\"].accuracy)\nplt.show()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "plt.plot(scores[scores.phase==\"train\"].epoch, scores[scores.phase==\"train\"].log_loss)\nplt.plot(scores[scores.phase==\"test\"].epoch, scores[scores.phase==\"test\"].log_loss)\nplt.show()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_numeric_submit = test_df[numeric_features].values",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_numeric_submit.shape",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_text_submit = np.zeros((418, max_name_length + max_ticket_length + max_embarked_length))",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "for e, i in enumerate(test_df[text_features].iterrows()):\n    name = i[1][\"Name\"].lower()\n    ticket = i[1][\"Ticket\"].lower()\n    emb = i[1][\"Embarked\"].lower()\n    for p, w in enumerate(name):\n        X_text_submit[e, p] = vocab[w]\n    for p, w in enumerate(ticket):\n        X_text_submit[e, p + max_name_length] = vocab[w]\n    for p, w in enumerate(emb):\n        X_text_submit[e, p + max_name_length + max_ticket_length] = vocab[w] ",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "X_text_submit.shape",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "submit_probas = model.predict([X_numeric_submit, X_text_submit])[0]",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "np.mean(submit_probas > 0.5)",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "test_df.head()",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#print(\"PassengerId,Survived\")\n#for i, s in zip(test_df.PassengerId.values, submit_probas):\n#    print(i, 1 if s > 0.5 else 0, sep=\",\")",
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  }
 ]
}